{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 04 - Tidy data \n",
    " What is Tidy Data?\n",
    "\n",
    " Tidy data is a structured format where:\n",
    "\n",
    "     - Each row represents one observation (e.g., a country in a given year).\n",
    "     - Each column is a variable (e.g., GDP, life expectancy).\n",
    "     - Each table represents a dataset (e.g., economic statistics).\n",
    "\n",
    " ðŸ’¡ Why use tidy data?\n",
    " \n",
    "     - Easier to analyze: Works well with `groupby()`, `agg()`, and visualization libraries like Seaborn.\n",
    "     - More readable: No redundant columns.\n",
    "     - Plays nicely with Pandas and Seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Wide Format to Tidy (Long) Format\n",
    "\n",
    " In the dataset below, **each year's population** is in a **separate column**, which makes it a **wide format**.\n",
    "\n",
    " We can convert it to **tidy** format using `pd.melt()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# population over time\n",
    "df = pd.DataFrame({\n",
    "    \"country\": [\"USA\", \"Canada\", \"Brazil\"],\n",
    "    \"1990\": [253, 28, 149],\n",
    "    \"2000\": [282, 31, 170],\n",
    "    \"2010\": [309, 34, 192],\n",
    "    \"2020\": [339, 38, 209],\n",
    "    # \"continent\": [\"North America\", \"North America\", \"South America\"],\n",
    "})\n",
    "\n",
    "# Wide format\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### `pd.melt()`\n",
    "\n",
    " - `id_vars`: The columns that **stay the same** (identifiers).\n",
    "\n",
    " - `var_name`: Name of the **new column** that will hold the old column headers (years).\n",
    "\n",
    " - `value_name`: Name of the new column that will store the values (population in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tidy = df.melt(id_vars=[\"country\"], var_name=\"year\", value_name=\"population\")\n",
    "display(df_tidy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Notice how each row now represents **one country** in **one year**, and each column is **a single variable**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Converting Tidy (Long) Format Back to Wide Format\n",
    "\n",
    " - If you ever need to go back to **wide** format, you can use `pivot()` or `pivot_table()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = df_tidy.pivot(index=\"country\", columns=\"year\", values=\"population\")\n",
    "display(df_wide)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Here, each row is a **country**, and each column is a **year**â€”back to wide format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Summarizing Tidy Data with `groupby()`\n",
    "\n",
    " Tidy data makes it straightforward to **group** and **summarize**.\n",
    "\n",
    "\n",
    "\n",
    " ### `groupby(\"year\")[\"population\"].mean()`\n",
    "\n",
    " This computes the **mean population** for each year across **all countries**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,data in df_tidy.groupby(\"year\"):\n",
    "    display(key)\n",
    "    display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_year_mean = df_tidy.groupby(\"year\")[\"population\"].std()\n",
    "display(df_year_mean)\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Grouping by Multiple Columns\n",
    "\n",
    " We can also group by **both** `year` **and** `country`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_year_country_sum = df_tidy.groupby([\"year\", \"country\"])[\"population\"].sum()\n",
    "display(df_year_country_sum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This returns a **multi-index Series**, showing the population **by year and by country**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## `agg()` for Multiple Summaries\n",
    "\n",
    " The `agg()` function lets us apply **multiple aggregations** at once.\n",
    "\n",
    " For instance, we can find the **mean** and the **max** population per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_tidy.groupby(\"year\").agg({\"population\": [\"mean\", \"max\",\"sum\"]})\n",
    "display(df_agg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This shows the average (`mean`) population and the maximum (`max`) population in each **year**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Handling Missing Data\n",
    "\n",
    " Let's introduce some **missing values** to demonstrate `dropna()` and `fillna()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy with artificially introduced NaNs\n",
    "df_missing = df_tidy.copy()\n",
    "df_missing.loc[(df_missing[\"country\"] == \"Brazil\") & (df_missing[\"year\"] == \"2020\"), \"population\"] = None\n",
    "\n",
    "display(df_missing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### `dropna()`\n",
    "\n",
    " - **Removes** rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df_missing.dropna(subset=[\"population\"])\n",
    "display(df_dropped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Brazil's 2020 row is **completely removed** because of the missing population.\n",
    "\n",
    "\n",
    "\n",
    " ### `fillna()`\n",
    "\n",
    " - **Fills** missing values with a specified value or method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled = df_missing.fillna(0)\n",
    "display(df_filled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, the missing value is replaced with `0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Combining Data with `merge()`\n",
    "\n",
    " Often, you'll have **multiple DataFrames** that need to be joined.\n",
    "\n",
    " Below is an example for merging a **GDP** dataset with our **population** dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_data = pd.DataFrame({\n",
    "    \"country\": [\"USA\", \"Canada\", \"Brazil\"],\n",
    "    \"year\": [\"2020\", \"2020\", \"2020\"],\n",
    "    \"gdp\": [21439, 1736, 1445],  # GDP in billions (fictitious or approximate)\n",
    "})\n",
    "\n",
    "# Merging on both country and year\n",
    "df_merged = df_tidy.merge(gdp_data, on=[\"country\", \"year\"], how=\"left\")\n",
    "display(df_merged)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We used `how=\"left\"` so that **all rows from `df_tidy`** are preserved, even if some may not match in `gdp_data`.\n",
    "\n",
    "\n",
    "\n",
    " - `how=\"inner\"` would only keep matching rows.\n",
    "\n",
    " - `how=\"outer\"` keeps **all** rows from both DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Example: `sort_values()` and `query()`\n",
    "\n",
    " Tidy data also makes it easy to **sort** and **filter**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by population descending\n",
    "df_sorted = df_tidy.sort_values(\"population\", ascending=False)\n",
    "display(df_sorted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### `query()`\n",
    "\n",
    " An alternative way to filter rows:\n",
    "\n",
    "\n",
    "\n",
    " ```python\n",
    "\n",
    " df.query(\"population > 200 and country == 'USA'\")\n",
    "\n",
    " ```\n",
    "\n",
    "\n",
    "\n",
    " is equivalent to\n",
    "\n",
    "\n",
    "\n",
    " ```python\n",
    "\n",
    " df[(df[\"population\"] > 200) & (df[\"country\"] == \"USA\")]\n",
    "\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_tidy.query(\"population > 200 and country == 'USA'\")\n",
    "display(df_filtered)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Tidy and Process the Billboard Dataset\n",
    "\n",
    "\n",
    "\n",
    " The Billboard dataset comes with **76 columns** corresponding to the chart position of each song from `x1st.week` through `x76th.week`. This is a classic example of **wide** data that needs to be **melted** (unpivoted) into a long (tidy) format.\n",
    "\n",
    "\n",
    "\n",
    " ### Goals\n",
    "\n",
    " 1. **Load** the Billboard dataset from CSV.\n",
    "\n",
    " 2. **Tidy** the data so each row represents one song in one week.\n",
    "\n",
    " 3. **Calculate** the actual date for each week using `date.entered + week * 7 days`.\n",
    "\n",
    " 4. **Split** the data into two tables:\n",
    "\n",
    "    - A **songs** table with static song information.\n",
    "\n",
    "    - A **positions** table with `(song_id, week, rank, date)`.\n",
    "\n",
    " 5. **Save** the tidy data to **Feather** format in the same directory with `_tidy` suffix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load the Billboard dataset\n",
    "df_bill = pd.read_csv(\"../../Datasets/billboard.csv\")\n",
    "\n",
    "# Let's check a few columns to see the structure.\n",
    "df_bill.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The dataset has columns like:\n",
    "\n",
    " - **year**, **artist.inverted**, **track**, **time**, **genre** â€¦ (song info)\n",
    "\n",
    " - **date.entered**, **date.peaked** â€¦ (chart-related dates)\n",
    "\n",
    " - **x1st.week** through **x76th.week** â€¦ (chart positions over 76 weeks)\n",
    "\n",
    "\n",
    "\n",
    " We want to **melt** these weekly columns into a single `week` and `rank` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Notice how each row is now **one song** in **one week**. However, the `week` column currently contains strings like `\"x1st.week\"`, `\"x2nd.week\"`, etc. Let's clean those up and create a numeric week column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, `week = 1, 2, 3, ... 76`. Next, we want to calculate the **exact date** on the chart for each row by adding `week * 7` days to `date.entered`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Split into Two Tables\n",
    "\n",
    "\n",
    "\n",
    " **Why split?** We often separate the **static** song info (e.g., artist, track, time, genre) from the **weekly** chart performance (week, rank, date).\n",
    "\n",
    "\n",
    "\n",
    " - **Songs Table**: Contains unique identifiers for each song plus basic metadata.\n",
    "\n",
    " - **Positions Table**: Contains `(song_id, week, rank, date)`, referencing the **song_id** from the songs table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Next, we merge this `song_id` back into our `df_tidy` so we can create the positions table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Create the Positions Table\n",
    "\n",
    "\n",
    "\n",
    " We only keep the **relevant columns** for weekly positions: `song_id`, `week`, `rank`, and `date`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.Playing with the data\n",
    " Now that we have our data in a tidy format, let's do some analysis.\n",
    "\n",
    "### Only songs that reached top 10\n",
    "We can use `query()` to filter the data for songs that reached the top 10 at least once. We will merge this back to the songs table to get the song details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to remove duplicates to get a list of unique songs that reached the top 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How long did each song stay in the top 10?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In which week did each song reach the top 10?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 9. Save Tidy Data to Feather\n",
    "\n",
    "\n",
    "\n",
    " We want to save:\n",
    "\n",
    " - The **tidy** DataFrame (`df_tidy`) to a single file with the suffix `_tidy`.\n",
    "\n",
    " - (Optionally) Also save **songs** and **positions** as separate Feather files if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usableai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
